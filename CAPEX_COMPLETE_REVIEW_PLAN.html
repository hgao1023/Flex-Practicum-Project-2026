<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CapEx Intelligence System - Complete Review Plan</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 40px;
            background: #fff;
        }
        
        h1 {
            color: #1a365d;
            font-size: 2.2em;
            margin-bottom: 10px;
            padding-bottom: 15px;
            border-bottom: 3px solid #3182ce;
        }
        
        h2 {
            color: #2c5282;
            font-size: 1.6em;
            margin-top: 40px;
            margin-bottom: 15px;
            padding-bottom: 8px;
            border-bottom: 2px solid #bee3f8;
        }
        
        h3 {
            color: #2b6cb0;
            font-size: 1.3em;
            margin-top: 25px;
            margin-bottom: 10px;
        }
        
        h4 {
            color: #4a5568;
            font-size: 1.1em;
            margin-top: 20px;
            margin-bottom: 8px;
        }
        
        p {
            margin-bottom: 12px;
        }
        
        .subtitle {
            color: #718096;
            font-size: 1.1em;
            margin-bottom: 30px;
        }
        
        .highlight-box {
            background: linear-gradient(135deg, #ebf8ff 0%, #bee3f8 100%);
            border-left: 4px solid #3182ce;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 8px 8px 0;
        }
        
        .warning-box {
            background: linear-gradient(135deg, #fffaf0 0%, #feebc8 100%);
            border-left: 4px solid #dd6b20;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 8px 8px 0;
        }
        
        .critical-box {
            background: linear-gradient(135deg, #fff5f5 0%, #fed7d7 100%);
            border-left: 4px solid #c53030;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 8px 8px 0;
        }
        
        .success-box {
            background: linear-gradient(135deg, #f0fff4 0%, #c6f6d5 100%);
            border-left: 4px solid #38a169;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 8px 8px 0;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 0.95em;
        }
        
        th {
            background: #2c5282;
            color: white;
            padding: 12px;
            text-align: left;
            font-weight: 600;
        }
        
        td {
            padding: 10px 12px;
            border-bottom: 1px solid #e2e8f0;
        }
        
        tr:nth-child(even) {
            background: #f7fafc;
        }
        
        tr:hover {
            background: #edf2f7;
        }
        
        code {
            background: #edf2f7;
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 0.9em;
        }
        
        pre {
            background: #1a202c;
            color: #e2e8f0;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 15px 0;
            font-size: 0.85em;
            line-height: 1.5;
        }
        
        ul, ol {
            margin: 15px 0 15px 25px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        .team-card {
            background: white;
            border: 1px solid #e2e8f0;
            border-radius: 12px;
            padding: 25px;
            margin: 20px 0;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
        }
        
        .team-card h3 {
            color: #2c5282;
            margin-top: 0;
        }
        
        .badge {
            display: inline-block;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.8em;
            font-weight: 600;
            margin-right: 8px;
        }
        
        .badge-critical { background: #fed7d7; color: #c53030; }
        .badge-high { background: #feebc8; color: #c05621; }
        .badge-medium { background: #fefcbf; color: #975a16; }
        .badge-low { background: #c6f6d5; color: #276749; }
        
        .page-break {
            page-break-before: always;
        }
        
        .toc {
            background: #f7fafc;
            padding: 25px;
            border-radius: 8px;
            margin: 30px 0;
        }
        
        .toc h3 {
            margin-top: 0;
            color: #2c5282;
        }
        
        .toc ul {
            list-style: none;
            margin-left: 0;
        }
        
        .toc li {
            padding: 5px 0;
            border-bottom: 1px dotted #cbd5e0;
        }
        
        .checklist {
            list-style: none;
            margin-left: 0;
        }
        
        .checklist li {
            padding: 8px 0;
            padding-left: 30px;
            position: relative;
        }
        
        .checklist li::before {
            content: "‚òê";
            position: absolute;
            left: 0;
            color: #4a5568;
        }
        
        .metric-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 15px;
            margin: 20px 0;
        }
        
        .metric-card {
            background: #f7fafc;
            padding: 20px;
            border-radius: 8px;
            text-align: center;
            border: 1px solid #e2e8f0;
        }
        
        .metric-value {
            font-size: 2em;
            font-weight: 700;
            color: #2c5282;
        }
        
        .metric-label {
            color: #718096;
            font-size: 0.9em;
        }
        
        @media print {
            body {
                padding: 20px;
            }
            .page-break {
                page-break-before: always;
            }
        }
    </style>
</head>
<body>

<h1>CapEx Intelligence System</h1>
<p class="subtitle">Complete Code Review & Improvement Plan</p>

<div class="highlight-box">
    <strong>Team Size:</strong> 4 people (3 technical + 1 QA)<br>
    <strong>System:</strong> Python + Ollama (llama3.1:8b) + ChromaDB + Streamlit<br>
    <strong>Goal:</strong> Systematically identify and fix accuracy issues<br>
    <strong>Timeline:</strong> 3 weeks
</div>

<div class="toc">
    <h3>Table of Contents</h3>
    <ul>
        <li><strong>Part 1:</strong> Team Assignments & Overview</li>
        <li><strong>Part 2:</strong> Person 1 - Text Extraction & Classification</li>
        <li><strong>Part 3:</strong> Person 2 - RAG & Vector Search</li>
        <li><strong>Part 4:</strong> Person 3 - AI Extraction & Data Quality</li>
        <li><strong>Part 5:</strong> Lucas - Documentation & QA Lead</li>
        <li><strong>Part 6:</strong> Known Issues & Prioritization</li>
        <li><strong>Part 7:</strong> Improvement Roadmap</li>
        <li><strong>Part 8:</strong> Quick Start Commands</li>
    </ul>
</div>

<!-- PART 1: TEAM OVERVIEW -->
<h2>Part 1: Team Assignments & Overview</h2>

<div class="metric-grid">
    <div class="metric-card">
        <div class="metric-value">4</div>
        <div class="metric-label">Team Members</div>
    </div>
    <div class="metric-card">
        <div class="metric-value">3</div>
        <div class="metric-label">Weeks</div>
    </div>
    <div class="metric-card">
        <div class="metric-value">8</div>
        <div class="metric-label">Known Issues</div>
    </div>
    <div class="metric-card">
        <div class="metric-value">+78%</div>
        <div class="metric-label">Expected Accuracy Gain</div>
    </div>
</div>

<h3>Team Roles</h3>

<table>
    <tr>
        <th>Person</th>
        <th>Role</th>
        <th>Focus Area</th>
        <th>Technical Level</th>
    </tr>
    <tr>
        <td><strong>Person 1</strong></td>
        <td>Text Extraction & Classification</td>
        <td>PDF parsing, document classification</td>
        <td>High</td>
    </tr>
    <tr>
        <td><strong>Person 2</strong></td>
        <td>RAG & Vector Search</td>
        <td>ChromaDB, retrieval, chunking</td>
        <td>High</td>
    </tr>
    <tr>
        <td><strong>Person 3</strong></td>
        <td>AI Extraction & Data Quality</td>
        <td>Prompts, JSON parsing, validation</td>
        <td>High</td>
    </tr>
    <tr>
        <td><strong>Lucas</strong></td>
        <td>Documentation & QA Lead</td>
        <td>Ground truth, manual validation</td>
        <td>Low (no coding)</td>
    </tr>
</table>

<h3>Files to Review</h3>

<pre>
project/
‚îú‚îÄ‚îÄ extraction/
‚îÇ   ‚îú‚îÄ‚îÄ pdf_extractor.py          # Person 1
‚îÇ   ‚îú‚îÄ‚îÄ html_extractor.py         # Person 1
‚îÇ   ‚îú‚îÄ‚îÄ document_classifier.py    # Person 1
‚îÇ   ‚îî‚îÄ‚îÄ ai_extractor.py           # Person 3
‚îú‚îÄ‚îÄ rag/
‚îÇ   ‚îú‚îÄ‚îÄ retriever.py              # Person 2
‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py           # Person 2
‚îÇ   ‚îú‚îÄ‚îÄ chunker.py                # Person 2
‚îÇ   ‚îî‚îÄ‚îÄ embeddings.py             # Person 2
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îî‚îÄ‚îÄ extraction_prompts.py     # Person 3
‚îî‚îÄ‚îÄ ground_truth/
    ‚îî‚îÄ‚îÄ ground_truth_lucas.csv    # Lucas
</pre>

<!-- PART 2: PERSON 1 -->
<div class="page-break"></div>
<h2>Part 2: Person 1 - Text Extraction & Classification</h2>

<div class="team-card">
    <h3>üéØ Goals</h3>
    <ul>
        <li>Test PDF extraction quality on 15+ documents</li>
        <li>Measure document classification accuracy</li>
        <li>Identify table extraction issues</li>
        <li>Recommend fixes for multi-column text</li>
    </ul>
</div>

<h3>Review Checklist</h3>

<h4>A. PDF/HTML Extraction Quality</h4>
<table>
    <tr>
        <th>Check</th>
        <th>Status</th>
        <th>Notes</th>
    </tr>
    <tr><td>Multi-column text in correct reading order</td><td>‚òê</td><td></td></tr>
    <tr><td>Tables extracted with structure preserved</td><td>‚òê</td><td></td></tr>
    <tr><td>Headers/footers properly excluded</td><td>‚òê</td><td></td></tr>
    <tr><td>Page numbers removed</td><td>‚òê</td><td></td></tr>
    <tr><td>Special characters handled</td><td>‚òê</td><td></td></tr>
    <tr><td>Numbers not split from context</td><td>‚òê</td><td></td></tr>
</table>

<h4>B. Document Classification</h4>
<table>
    <tr>
        <th>Check</th>
        <th>Status</th>
        <th>Notes</th>
    </tr>
    <tr><td>10-K vs 10-Q correctly distinguished</td><td>‚òê</td><td></td></tr>
    <tr><td>Company name extraction accurate</td><td>‚òê</td><td></td></tr>
    <tr><td>Fiscal year correctly identified</td><td>‚òê</td><td></td></tr>
    <tr><td>Quarter correctly identified</td><td>‚òê</td><td></td></tr>
</table>

<h3>Common Issues to Find</h3>

<div class="warning-box">
    <strong>Issue: Multi-Column Text Garbled</strong><br>
    PyPDF2 extracts text left-to-right across the page, not column-by-column.<br><br>
    <strong>Fix:</strong> Switch to pdfplumber with layout-aware extraction:<br>
    <code>page.extract_text(layout=True)</code>
</div>

<div class="warning-box">
    <strong>Issue: 10-K vs 10-Q Confusion</strong><br>
    Both document types contain similar keywords like "quarterly".<br><br>
    <strong>Fix:</strong> Check for "FORM 10-K" or "FORM 10-Q" in filing header instead of keyword matching.
</div>

<h3>Test Code</h3>
<pre>
# test_classification.py
def test_document_classification():
    test_cases = [
        ("Flex_10K_2024.pdf", {"doc_type": "10-K", "company": "Flex"}),
        ("Flex_10Q_Q1_2024.pdf", {"doc_type": "10-Q", "quarter": 1}),
    ]
    
    for file, expected in test_cases:
        result = classify_document(file)
        for field, value in expected.items():
            assert result[field] == value, f"Mismatch: {field}"
</pre>

<h3>Deliverables</h3>
<ul class="checklist">
    <li>Classification accuracy report (target: >90%)</li>
    <li>List of extraction issues with examples</li>
    <li>Proposed fixes with code snippets</li>
    <li>Time estimates for each fix</li>
</ul>

<!-- PART 3: PERSON 2 -->
<div class="page-break"></div>
<h2>Part 3: Person 2 - RAG & Vector Search</h2>

<div class="team-card">
    <h3>üéØ Goals</h3>
    <ul>
        <li>Test retrieval accuracy on 20+ queries</li>
        <li>Identify cross-company contamination</li>
        <li>Optimize chunk size and overlap</li>
        <li>Verify metadata filtering works</li>
    </ul>
</div>

<h3>Review Checklist</h3>

<table>
    <tr>
        <th>Check</th>
        <th>Status</th>
        <th>Notes</th>
    </tr>
    <tr><td>Correct documents returned for specific queries</td><td>‚òê</td><td></td></tr>
    <tr><td>Relevant chunks ranked in top-5</td><td>‚òê</td><td></td></tr>
    <tr><td>Company filtering works correctly</td><td>‚òê</td><td></td></tr>
    <tr><td>No cross-company contamination</td><td>‚òê</td><td></td></tr>
    <tr><td>Chunk boundaries don't split numbers</td><td>‚òê</td><td></td></tr>
    <tr><td>Metadata properly indexed</td><td>‚òê</td><td></td></tr>
</table>

<h3>Test Queries</h3>
<table>
    <tr>
        <th>Query</th>
        <th>Expected Company</th>
        <th>Keywords to Find</th>
    </tr>
    <tr>
        <td>"Flex capital expenditure fiscal 2024"</td>
        <td>Flex</td>
        <td>capex, capital, expenditure</td>
    </tr>
    <tr>
        <td>"Jabil revenue 2024"</td>
        <td>Jabil</td>
        <td>revenue, sales</td>
    </tr>
    <tr>
        <td>"Celestica data center investments"</td>
        <td>Celestica</td>
        <td>data center, AI</td>
    </tr>
</table>

<h3>Common Issues to Find</h3>

<div class="critical-box">
    <strong>Issue: Cross-Company Contamination</strong><br>
    Query for "Flex capital expenditure" returns Jabil documents in top results.<br><br>
    <strong>Fix:</strong> Detect company from query and add metadata filter:
    <pre>
where_filter = {"company": detected_company}
results = collection.query(..., where=where_filter)
    </pre>
</div>

<div class="warning-box">
    <strong>Issue: Chunk Boundary Splits Numbers</strong><br>
    "Capital expenditures" appears in one chunk, "$505 million" in the next.<br><br>
    <strong>Fix:</strong> Use sentence-aware chunking with overlap.
</div>

<h3>Metrics to Calculate</h3>
<table>
    <tr>
        <th>Metric</th>
        <th>Formula</th>
        <th>Target</th>
    </tr>
    <tr>
        <td>Precision@5</td>
        <td>Relevant in top 5 / 5</td>
        <td>>80%</td>
    </tr>
    <tr>
        <td>Recall</td>
        <td>Retrieved relevant / Total relevant</td>
        <td>>70%</td>
    </tr>
    <tr>
        <td>MRR</td>
        <td>1 / Rank of first relevant</td>
        <td>>0.5</td>
    </tr>
    <tr>
        <td>Success Rate</td>
        <td>Queries with at least 1 relevant</td>
        <td>>90%</td>
    </tr>
</table>

<h3>Deliverables</h3>
<ul class="checklist">
    <li>Retrieval accuracy report with metrics</li>
    <li>Chunk size optimization results</li>
    <li>Cross-company contamination analysis</li>
    <li>Recommended configuration changes</li>
</ul>

<!-- PART 4: PERSON 3 -->
<div class="page-break"></div>
<h2>Part 4: Person 3 - AI Extraction & Data Quality</h2>

<div class="team-card">
    <h3>üéØ Goals</h3>
    <ul>
        <li>Test extraction accuracy against ground truth</li>
        <li>Identify YTD vs quarterly confusion</li>
        <li>Fix negative number handling</li>
        <li>Improve extraction prompts</li>
    </ul>
</div>

<h3>Review Checklist</h3>

<table>
    <tr>
        <th>Check</th>
        <th>Status</th>
        <th>Notes</th>
    </tr>
    <tr><td>CapEx values match source documents</td><td>‚òê</td><td></td></tr>
    <tr><td>YTD vs quarterly correctly distinguished</td><td>‚òê</td><td></td></tr>
    <tr><td>Negative numbers handled correctly</td><td>‚òê</td><td></td></tr>
    <tr><td>Alternative CapEx labels recognized</td><td>‚òê</td><td></td></tr>
    <tr><td>JSON parsing handles edge cases</td><td>‚òê</td><td></td></tr>
    <tr><td>Prompts are specific enough</td><td>‚òê</td><td></td></tr>
</table>

<h3>Critical Issues</h3>

<div class="critical-box">
    <strong>Issue: YTD vs Quarterly Confusion</strong><br>
    System extracts YTD ($380M for 9 months) instead of quarterly ($127M for Q3 only).<br>
    <strong>Impact:</strong> 2-3x overstatement of quarterly CapEx<br><br>
    <strong>Fix:</strong> Update prompt with explicit period instructions:
    <pre>
For 10-Q filings, distinguish between:
- "Three months ended" ‚Üí quarterly (single quarter)
- "Nine months ended" ‚Üí YTD (cumulative)

Return ONLY the quarterly value, not YTD.
    </pre>
</div>

<div class="warning-box">
    <strong>Issue: Negative Number Handling</strong><br>
    CapEx shown as (505) or -505 in cash flow statements extracted incorrectly.<br><br>
    <strong>Fix:</strong> Add regex preprocessing:
    <pre>
# Convert (505) to 505
value = re.sub(r'\((\d+)\)', r'\1', value)
value = abs(float(value))
    </pre>
</div>

<h3>CapEx Label Variations</h3>
<p>The prompt must recognize ALL of these:</p>
<ul>
    <li>"Capital expenditures"</li>
    <li>"Purchases of property, plant and equipment"</li>
    <li>"Additions to property, plant and equipment"</li>
    <li>"Payments for property, plant and equipment"</li>
    <li>"Investments in property, plant and equipment"</li>
</ul>

<h3>Improved Prompt Template</h3>
<pre>
Extract capital expenditure (CapEx) from this SEC filing.

IMPORTANT:
1. Look in Cash Flow Statement > Investing Activities
2. CapEx is typically NEGATIVE (cash outflow) - convert to POSITIVE
3. For 10-Q: Extract QUARTERLY value ("Three months"), not YTD

Common labels:
- "Capital expenditures"
- "Purchases of property, plant and equipment"

OUTPUT FORMAT:
{
  "capital_expenditures": {
    "value": &lt;number in millions&gt;,
    "period_type": "quarterly" | "annual",
    "confidence": "high" | "low"
  }
}
</pre>

<h3>Deliverables</h3>
<ul class="checklist">
    <li>Extraction accuracy report (target: >90%)</li>
    <li>Updated prompts with period handling</li>
    <li>JSON parser fixes for edge cases</li>
    <li>Before/after accuracy comparison</li>
</ul>

<!-- PART 5: LUCAS -->
<div class="page-break"></div>
<h2>Part 5: Lucas - Documentation & QA Lead</h2>

<div class="team-card">
    <h3>üéØ Role Overview</h3>
    <p><strong>Time Commitment:</strong> 5-7 hours/week (evenings/weekends)</p>
    <p><strong>Technical Level:</strong> Low (no coding required)</p>
    <p><strong>Impact:</strong> Critical - provides ground truth for accuracy testing</p>
</div>

<h3>Three Main Responsibilities</h3>

<table>
    <tr>
        <th>Responsibility</th>
        <th>Time</th>
        <th>Description</th>
    </tr>
    <tr>
        <td><strong>1. Documentation Coordinator</strong></td>
        <td>2-3 hrs/week</td>
        <td>Collect findings, maintain tracker, compile reports</td>
    </tr>
    <tr>
        <td><strong>2. Manual Validation</strong></td>
        <td>2-3 hrs/week</td>
        <td>Verify extracted data against actual PDFs</td>
    </tr>
    <tr>
        <td><strong>3. Ground Truth Creator</strong></td>
        <td>2-3 hrs (one-time)</td>
        <td>Create "answer key" dataset</td>
    </tr>
</table>

<h3>Weekly Schedule</h3>

<table>
    <tr>
        <th>Day</th>
        <th>Time</th>
        <th>Tasks</th>
    </tr>
    <tr>
        <td>Monday</td>
        <td>1 hour</td>
        <td>Set up/update tracker, send reminders</td>
    </tr>
    <tr>
        <td>Wednesday</td>
        <td>1.5 hours</td>
        <td>Collect updates, validate 5 documents</td>
    </tr>
    <tr>
        <td>Friday</td>
        <td>1.5 hours</td>
        <td>Validate 5 docs, compile weekly report</td>
    </tr>
    <tr>
        <td>Weekend</td>
        <td>2 hours</td>
        <td>Additional validation, polish report</td>
    </tr>
</table>

<h3>Document Validation Process</h3>

<div class="highlight-box">
    <strong>Per Document (10-12 minutes):</strong>
    <ol>
        <li>Open PDF in Preview/Acrobat</li>
        <li>Press Ctrl+F, search "cash flow"</li>
        <li>Find "Purchases of property and equipment" line</li>
        <li>Write down the number (e.g., $505M)</li>
        <li>Compare to system's extracted value</li>
        <li>Record result in tracker</li>
    </ol>
</div>

<h3>Ground Truth CSV Format</h3>
<pre>
filename,company,fiscal_year,quarter,actual_capex,page_number,notes
Flex_10K_FY2024.pdf,Flex,2024,,505,67,"Found in Investing Activities"
Flex_10Q_Q1_2024.pdf,Flex,2024,Q1,127,12,"Quarterly only, not YTD"
Jabil_10K_2024.pdf,Jabil,2024,,700,62,"Listed as Capital expenditures"
</pre>

<h3>Success Metrics</h3>
<ul class="checklist">
    <li>Week 1: 15 documents validated, ground truth created</li>
    <li>Week 2: 15 more documents, ground truth expanded to 30</li>
    <li>Week 3: Validate fixes, measure improvement</li>
</ul>

<!-- PART 6: ISSUES -->
<div class="page-break"></div>
<h2>Part 6: Known Issues & Prioritization</h2>

<h3>Issue Summary</h3>

<table>
    <tr>
        <th>ID</th>
        <th>Issue</th>
        <th>Severity</th>
        <th>Impact</th>
        <th>Fix Time</th>
    </tr>
    <tr>
        <td>EXT-001</td>
        <td>YTD vs Quarterly Confusion</td>
        <td><span class="badge badge-critical">CRITICAL</span></td>
        <td>+25%</td>
        <td>4 hrs</td>
    </tr>
    <tr>
        <td>EXT-002</td>
        <td>Negative Number Handling</td>
        <td><span class="badge badge-high">HIGH</span></td>
        <td>+15%</td>
        <td>2 hrs</td>
    </tr>
    <tr>
        <td>RET-001</td>
        <td>Cross-Company Contamination</td>
        <td><span class="badge badge-high">HIGH</span></td>
        <td>+12%</td>
        <td>3 hrs</td>
    </tr>
    <tr>
        <td>CLS-001</td>
        <td>10-K vs 10-Q Misclassification</td>
        <td><span class="badge badge-high">HIGH</span></td>
        <td>+8%</td>
        <td>2 hrs</td>
    </tr>
    <tr>
        <td>EXT-003</td>
        <td>Alternative CapEx Labels</td>
        <td><span class="badge badge-medium">MEDIUM</span></td>
        <td>+7%</td>
        <td>1 hr</td>
    </tr>
    <tr>
        <td>PDF-001</td>
        <td>Multi-Column PDF Extraction</td>
        <td><span class="badge badge-medium">MEDIUM</span></td>
        <td>+6%</td>
        <td>3 hrs</td>
    </tr>
    <tr>
        <td>RET-002</td>
        <td>Chunk Boundary Issues</td>
        <td><span class="badge badge-medium">MEDIUM</span></td>
        <td>+5%</td>
        <td>4 hrs</td>
    </tr>
    <tr>
        <td>PERF-001</td>
        <td>Slow Embedding Generation</td>
        <td><span class="badge badge-low">LOW</span></td>
        <td>0%</td>
        <td>2 hrs</td>
    </tr>
</table>

<h3>ROI Ranking (Accuracy Gain per Hour)</h3>

<table>
    <tr>
        <th>Rank</th>
        <th>Issue</th>
        <th>Impact</th>
        <th>Hours</th>
        <th>ROI</th>
    </tr>
    <tr>
        <td>1</td>
        <td>EXT-002: Negative Numbers</td>
        <td>+15%</td>
        <td>2</td>
        <td><strong>7.5</strong></td>
    </tr>
    <tr>
        <td>2</td>
        <td>EXT-003: Alt Labels</td>
        <td>+7%</td>
        <td>1</td>
        <td><strong>7.0</strong></td>
    </tr>
    <tr>
        <td>3</td>
        <td>EXT-001: YTD/Quarterly</td>
        <td>+25%</td>
        <td>4</td>
        <td><strong>6.25</strong></td>
    </tr>
    <tr>
        <td>4</td>
        <td>CLS-001: 10-K/10-Q</td>
        <td>+8%</td>
        <td>2</td>
        <td><strong>4.0</strong></td>
    </tr>
    <tr>
        <td>5</td>
        <td>RET-001: Contamination</td>
        <td>+12%</td>
        <td>3</td>
        <td><strong>4.0</strong></td>
    </tr>
</table>

<!-- PART 7: ROADMAP -->
<div class="page-break"></div>
<h2>Part 7: Improvement Roadmap</h2>

<h3>Sprint Plan</h3>

<table>
    <tr>
        <th>Sprint</th>
        <th>Issues</th>
        <th>Hours</th>
        <th>Accuracy Gain</th>
        <th>Cumulative</th>
    </tr>
    <tr>
        <td><strong>Sprint 1</strong></td>
        <td>EXT-001 (YTD), EXT-002 (Negative)</td>
        <td>6</td>
        <td>+40%</td>
        <td>+40%</td>
    </tr>
    <tr>
        <td><strong>Sprint 2</strong></td>
        <td>RET-001 (Contamination), CLS-001 (10-K/Q)</td>
        <td>5</td>
        <td>+20%</td>
        <td>+60%</td>
    </tr>
    <tr>
        <td><strong>Sprint 3</strong></td>
        <td>EXT-003 (Labels), PDF-001 (Multi-col)</td>
        <td>4</td>
        <td>+13%</td>
        <td>+73%</td>
    </tr>
    <tr>
        <td><strong>Sprint 4</strong></td>
        <td>RET-002 (Chunks), PERF-001 (Speed)</td>
        <td>6</td>
        <td>+5%</td>
        <td>+78%</td>
    </tr>
</table>

<h3>Weekly Timeline</h3>

<div class="success-box">
    <h4>Week 1: Testing & Ground Truth</h4>
    <ul>
        <li><strong>All:</strong> Run initial tests, measure baseline accuracy</li>
        <li><strong>Lucas:</strong> Create ground truth (15 documents)</li>
        <li><strong>Friday:</strong> Review findings, prioritize fixes</li>
    </ul>
</div>

<div class="highlight-box">
    <h4>Week 2: Fix Critical Issues</h4>
    <ul>
        <li><strong>Person 3:</strong> Fix YTD/quarterly, negative numbers</li>
        <li><strong>Person 2:</strong> Implement company filtering</li>
        <li><strong>Person 1:</strong> Fix classification logic</li>
        <li><strong>Lucas:</strong> Expand ground truth to 30 docs</li>
    </ul>
</div>

<div class="success-box">
    <h4>Week 3: Validate & Polish</h4>
    <ul>
        <li><strong>All:</strong> Re-test with fixes applied</li>
        <li><strong>Lucas:</strong> Validate improvements</li>
        <li><strong>Friday:</strong> Final report with before/after comparison</li>
    </ul>
</div>

<!-- PART 8: QUICK START -->
<div class="page-break"></div>
<h2>Part 8: Quick Start Commands</h2>

<h3>Setup (Everyone)</h3>
<pre>
# Install dependencies
pip install pytest pandas pdfplumber openpyxl --break-system-packages

# Create directories
mkdir -p test_data reports ground_truth
</pre>

<h3>Person 1: Classification Test</h3>
<pre>
cd ~/Documents/flex_practicum
python test_classification_real.py
python test_extraction_quality.py
</pre>

<h3>Person 2: Retrieval Test</h3>
<pre>
cd ~/Documents/flex_practicum
python test_retrieval_real.py
</pre>

<h3>Person 3: Extraction Test</h3>
<pre>
cd ~/Documents/flex_practicum
python ground_truth/create_ground_truth.py  # Create template
# ... fill in values manually ...
python test_extraction_real.py  # Test accuracy
</pre>

<h3>Lucas: Ground Truth</h3>
<pre>
mkdir ~/capex_review
cd ~/capex_review

# Create CSV
echo "filename,company,fiscal_year,quarter,actual_capex,page_number,notes" > ground_truth_lucas.csv

# Start validating documents!
</pre>

<h3>Team Coordination</h3>

<div class="highlight-box">
    <h4>Daily Standup (15 min)</h4>
    <p>Each person posts in Slack:</p>
    <ul>
        <li>What I tested yesterday</li>
        <li>Accuracy score found</li>
        <li>Top issue identified</li>
        <li>Blocker (if any)</li>
    </ul>
</div>

<div class="highlight-box">
    <h4>Friday Review (1 hour)</h4>
    <ol>
        <li>Each person presents findings (10 min each)</li>
        <li>Review accuracy scores (5 min)</li>
        <li>Prioritize top 3 issues (10 min)</li>
        <li>Assign fixes for next week (15 min)</li>
    </ol>
</div>

<hr style="margin-top: 50px;">

<p style="text-align: center; color: #718096; margin-top: 30px;">
    <strong>CapEx Intelligence System Review Plan</strong><br>
    Team of 4 | 3 Weeks | Target: +78% Accuracy
</p>

</body>
</html>
